{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f7ba05d1-9c71-433f-b437-99669f6462ad",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data written to: /Volumes/lastfmdata/bronze/csv_uploads/top_artists_20250709\nData written to: /Volumes/lastfmdata/bronze/csv_uploads/top_tracks_20250709\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import xml.etree.ElementTree as ET\n",
    "from datetime import datetime\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType\n",
    "\n",
    "# Setup\n",
    "spark = SparkSession.getActiveSession()\n",
    "api_key = \"**********************\"\n",
    "artist_tags = [\"name\", \"listeners\", \"mbid\", \"url\"]\n",
    "track_tags = [\"name\", \"duration\", \"listeners\", \"url\"]\n",
    "artist_nested_tags = [\"name\", \"mbid\", \"url\"]\n",
    "countries = [\"India\", \"United states\", \"Canada\", \"Spain\", \"Germany\", \"China\", \"Mexico\"]\n",
    "today = datetime.today().strftime('%Y%m%d')\n",
    "\n",
    "\n",
    "# Parse and return all artist rows\n",
    "def fetch_all_artists():\n",
    "    all_rows = []\n",
    "    for country in countries:\n",
    "        url = f\"https://ws.audioscrobbler.com/2.0/?method=geo.gettopartists&api_key={api_key}&country={country}\"\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        root = ET.fromstring(response.text)\n",
    "        artists = root.findall(\".//artist\")\n",
    "        for artist in artists:\n",
    "            row = {}\n",
    "            for tag in artist_tags:\n",
    "                el = artist.find(f\".//{tag}\")\n",
    "                row[tag] = el.text if el is not None else \"NULL\"\n",
    "            row[\"country\"] = country\n",
    "            all_rows.append(row)\n",
    "    return all_rows\n",
    "\n",
    "\n",
    "# Parse and return all track rows\n",
    "def fetch_all_tracks():\n",
    "    all_rows = []\n",
    "    for country in countries:\n",
    "        url = f\"https://ws.audioscrobbler.com/2.0/?method=geo.gettoptracks&api_key={api_key}&country={country}\"\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        root = ET.fromstring(response.text)\n",
    "        tracks = root.findall(\".//track\")\n",
    "        for track in tracks:\n",
    "            row = {}\n",
    "            for tag in track_tags:\n",
    "                el = track.find(f\".//{tag}\")\n",
    "                row[tag] = el.text if el is not None else \"NULL\"\n",
    "            for tag in artist_nested_tags:\n",
    "                el = track.find(f\".//artist/{tag}\")\n",
    "                row[f\"artist_{tag}\"] = el.text if el is not None else \"NULL\"\n",
    "            row[\"country\"] = country\n",
    "            all_rows.append(row)\n",
    "    return all_rows\n",
    "\n",
    "\n",
    "# Save DataFrame as single CSV file in Unity Catalog Volume\n",
    "def write_df_to_volume(df, path):\n",
    "    df.coalesce(1).write.option(\"header\", True).mode(\"overwrite\").csv(path)\n",
    "    print(f\"Data written to: {path}\")\n",
    "\n",
    "\n",
    "# Main Execution\n",
    "# Top Artists\n",
    "artist_rows = fetch_all_artists()\n",
    "artist_schema = StructType([StructField(tag, StringType(), True) for tag in artist_tags + [\"country\"]])\n",
    "df_artists = spark.createDataFrame(artist_rows, artist_schema)\n",
    "artist_volume_path = f\"/Volumes/lastfmdata/bronze/csv_uploads/top_artists_{today}\"\n",
    "write_df_to_volume(df_artists, artist_volume_path)\n",
    "\n",
    "# Top Tracks\n",
    "track_rows = fetch_all_tracks()\n",
    "all_tags = track_tags + [f\"artist_{t}\" for t in artist_nested_tags] + [\"country\"]\n",
    "track_schema = StructType([StructField(tag, StringType(), True) for tag in all_tags])\n",
    "df_tracks = spark.createDataFrame(track_rows, track_schema)\n",
    "track_volume_path = f\"/Volumes/lastfmdata/bronze/csv_uploads/top_tracks_{today}\"\n",
    "write_df_to_volume(df_tracks, track_volume_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "8be94549-3f44-4686-952e-3c5154d67ae4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "APIExtraction",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
